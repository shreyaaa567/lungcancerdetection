# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cBO9XK_zJTu5h-0BJ07qUQSDfNqvTQ2Z
"""

from google.colab import files

# Upload the ZIP file
uploaded = files.upload()

import zipfile

with zipfile.ZipFile("chest_ct_dataset.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/")

data_dir = "/content/Data"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

image_size = (224, 224)
batch_size = 32

train_generator = train_datagen.flow_from_directory(
    data_dir + "/train",
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    data_dir + "/valid",
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

import zipfile
import os

# Replace the filename below if it's different
zip_path = "chest_ct_dataset.zip"  # or "archive.zip" etc.

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/")

# Check the folder contents
os.listdir("/content/")

data_dir = "/content/Data"  # Change if your folder is named differently

# View what's inside to confirm it's the right path
os.listdir(data_dir)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image data preprocessing
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

image_size = (224, 224)
batch_size = 32

# Training data
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, "train"),
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

# Validation data
val_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, "valid"),
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

# (Optional) Test data
test_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, "test"),
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Flatten(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')  # Auto-detect number of classes
])

model.summary()

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

epochs = 10  # You can increase this later

history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=val_generator
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {accuracy*100:.2f}%")

model.save("lung_cancer_cnn_model.h5")

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

from google.colab import files
uploaded = files.upload()

import numpy as np
from tensorflow.keras.preprocessing import image

# Step 1: Replace this with your actual filename after upload
img_path = "000119.png"  # or the actual uploaded file name

# Step 2: Load and preprocess the image
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Normalize to [0,1]

# Step 3: Predict
prediction = model.predict(img_array)
predicted_class = np.argmax(prediction, axis=1)
class_labels = list(train_generator.class_indices.keys())  # same labels as training

# Step 4: Output result
print(f"Predicted Class: {class_labels[predicted_class[0]]}")

loss, acc = model.evaluate(test_generator)
print(f"Test Accuracy: {acc*100:.2f}%")

from tensorflow.keras.preprocessing import image
from google.colab import files
import numpy as np

# Upload an image from your PC
uploaded = files.upload()

for file_name in uploaded.keys():
    print(f"\nüìÇ Processing file: {file_name}")

    # Load and preprocess the image
    img = image.load_img(file_name, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    # Predict
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction, axis=1)[0]

    # Your class labels (make sure the order matches train_generator.class_indices)
    class_labels = list(train_generator.class_indices.keys())
    predicted_label = class_labels[predicted_class]

    # Custom Output
    if predicted_label.lower() == "normal":
        print("‚úÖ Prediction: Non-Cancerous")
    else:
        print(f"‚ö†Ô∏è Prediction: Cancerous ‚Äî Type: {predicted_label}")

model.save("lung_cancer_model.h5")

from google.colab import files
files.download("lung_cancer_model.h5")  # Download to local machine